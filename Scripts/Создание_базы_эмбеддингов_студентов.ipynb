{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByT5WjXiLmia",
        "outputId": "329a3945-2368-49df-f185-e5c00414bb2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "\n",
            "üì¶ –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏...\n",
            "‚úÖ –û–∫—Ä—É–∂–µ–Ω–∏–µ –≥–æ—Ç–æ–≤–æ!\n",
            "\n",
            "üì¶ –†–∞—Å–ø–∞–∫–æ–≤–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞...\n",
            "‚úÖ –†–∞—Å–ø–∞–∫–æ–≤–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞.\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "–Ø–ß–ï–ô–ö–ê 1: –ü–û–î–ì–û–¢–û–í–ö–ê –û–ö–†–£–ñ–ï–ù–ò–Ø –ò –î–ê–¢–ê–°–ï–¢–ê\n",
        "\"\"\"\n",
        "from google.colab import drive\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "# –ú–æ–Ω—Ç–∏—Ä—É–µ–º –¥–∏—Å–∫\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "print(\"\\nüì¶ –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏...\")\n",
        "!pip install -q insightface onnxruntime-gpu opencv-python\n",
        "print(\"‚úÖ –û–∫—Ä—É–∂–µ–Ω–∏–µ –≥–æ—Ç–æ–≤–æ!\\n\")\n",
        "\n",
        "# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø—É—Ç–µ–π\n",
        "ZIP_PATH = '/content/drive/MyDrive/students_prepared_dataset.zip'\n",
        "EXTRACT_PATH = '/content/students_data'\n",
        "MODEL_PATH = '/content/drive/MyDrive/student_embeddings.pkl'\n",
        "\n",
        "# –û—á–∏—Å—Ç–∫–∞ –∏ —Ä–∞—Å–ø–∞–∫–æ–≤–∫–∞\n",
        "if not os.path.exists(EXTRACT_PATH):\n",
        "    print(\"üì¶ –†–∞—Å–ø–∞–∫–æ–≤–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞...\")\n",
        "    os.makedirs(EXTRACT_PATH, exist_ok=True)\n",
        "    with zipfile.ZipFile(ZIP_PATH, 'r') as zip_ref:\n",
        "        zip_ref.extractall(EXTRACT_PATH)\n",
        "    print(\"‚úÖ –†–∞—Å–ø–∞–∫–æ–≤–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞.\")\n",
        "else:\n",
        "    print(\"‚úÖ –î–∞—Ç–∞—Å–µ—Ç —É–∂–µ —Ä–∞—Å–ø–∞–∫–æ–≤–∞–Ω.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "–Ø–ß–ï–ô–ö–ê 2: –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø –ò–ù–¢–ï–õ–õ–ï–ö–¢–ê\n",
        "\"\"\"\n",
        "import cv2\n",
        "import numpy as np\n",
        "from insightface.app import FaceAnalysis\n",
        "\n",
        "print(\"üöÄ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ InsightFace (buffalo_l)...\")\n",
        "# –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–∞–∑–º–µ—Ä 640x640, –∫–∞–∫ –≤ —Ç–≤–æ–µ–º —Å–∫—Ä–∏–ø—Ç–µ, –¥–ª—è –±–∞–ª–∞–Ω—Å–∞ —Å–∫–æ—Ä–æ—Å—Ç–∏ –∏ —Ç–æ—á–Ω–æ—Å—Ç–∏\n",
        "app = FaceAnalysis(name='buffalo_l', providers=['CUDAExecutionProvider'])\n",
        "app.prepare(ctx_id=0, det_size=(640, 640))\n",
        "print(\"‚úÖ –ú–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞ –∫ —Ä–∞–±–æ—Ç–µ –Ω–∞ GPU!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5zwErUEMEVt",
        "outputId": "af7ad9b9-9de7-4992-fee0-435e83bec75f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ InsightFace (buffalo_l)...\n",
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
            "find model: /root/.insightface/models/buffalo_l/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
            "find model: /root/.insightface/models/buffalo_l/2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
            "find model: /root/.insightface/models/buffalo_l/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
            "find model: /root/.insightface/models/buffalo_l/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
            "find model: /root/.insightface/models/buffalo_l/w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
            "set det-size: (640, 640)\n",
            "‚úÖ –ú–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞ –∫ —Ä–∞–±–æ—Ç–µ –Ω–∞ GPU!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "–Ø–ß–ï–ô–ö–ê 3: –ò–ó–í–õ–ï–ß–ï–ù–ò–ï –ü–†–ò–ó–ù–ê–ö–û–í\n",
        "\"\"\"\n",
        "from tqdm import tqdm\n",
        "\n",
        "def extract_raw_embeddings(data_dir):\n",
        "    raw_db = {}\n",
        "    students = [d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))]\n",
        "\n",
        "    print(f\"üë• –ù–∞–π–¥–µ–Ω–æ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {len(students)}\")\n",
        "\n",
        "    for student in tqdm(students, desc=\"–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\"):\n",
        "        student_dir = os.path.join(data_dir, student)\n",
        "        embeddings = []\n",
        "\n",
        "        for img_name in os.listdir(student_dir):\n",
        "            if not img_name.lower().endswith(('.jpg', '.png', '.jpeg')):\n",
        "                continue\n",
        "\n",
        "            img_path = os.path.join(student_dir, img_name)\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is None: continue\n",
        "\n",
        "            faces = app.get(img)\n",
        "            if not faces: continue\n",
        "\n",
        "            # –õ–æ–≥–∏–∫–∞ –∏–∑ —Ç–≤–æ–µ–≥–æ —Å–∫—Ä–∏–ø—Ç–∞: –±–µ—Ä–µ–º —Å–∞–º–æ–µ –∫—Ä—É–ø–Ω–æ–µ –ª–∏—Ü–æ\n",
        "            main_face = max(faces, key=lambda f: (f.bbox[2]-f.bbox[0]) * (f.bbox[3]-f.bbox[1]))\n",
        "\n",
        "            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —É–∂–µ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π –≤–µ–∫—Ç–æ—Ä\n",
        "            embeddings.append(main_face.normed_embedding)\n",
        "\n",
        "        if embeddings:\n",
        "            raw_db[student] = np.array(embeddings)\n",
        "\n",
        "    return raw_db\n",
        "\n",
        "raw_database = extract_raw_embeddings(EXTRACT_PATH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMQRO5igMFAM",
        "outputId": "e94e46fa-b7f0-4223-844f-5bdeabb1bf76"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üë• –ù–∞–π–¥–µ–Ω–æ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:06<00:00,  3.19s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "–Ø–ß–ï–ô–ö–ê 4: –§–û–†–ú–ò–†–û–í–ê–ù–ò–ï –ó–û–õ–û–¢–û–ô –ë–ê–ó–´ –ò –°–û–•–†–ê–ù–ï–ù–ò–ï\n",
        "\"\"\"\n",
        "import pickle\n",
        "\n",
        "def create_gold_embeddings(raw_embeddings_dict, percentile=75):\n",
        "    gold_embeddings = {}\n",
        "\n",
        "    print(\"‚ú® –û—á–∏—Å—Ç–∫–∞ –æ—Ç —à—É–º–∞ –∏ —Å–æ–∑–¥–∞–Ω–∏–µ —ç—Ç–∞–ª–æ–Ω–æ–≤...\")\n",
        "    for person_name, embeddings in raw_embeddings_dict.items():\n",
        "        if len(embeddings) < 3:\n",
        "            # –ï—Å–ª–∏ –º–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö - –ø—Ä–æ—Å—Ç–æ —É—Å—Ä–µ–¥–Ω—è–µ–º\n",
        "            centroid = np.mean(embeddings, axis=0)\n",
        "            gold_embeddings[person_name] = centroid / np.linalg.norm(centroid)\n",
        "            continue\n",
        "\n",
        "        # 1. –ß–µ—Ä–Ω–æ–≤–æ–π —Ü–µ–Ω—Ç—Ä–æ–∏–¥\n",
        "        initial_centroid = np.mean(embeddings, axis=0)\n",
        "        initial_centroid = initial_centroid / np.linalg.norm(initial_centroid)\n",
        "\n",
        "        # 2. –°—á–∏—Ç–∞–µ–º –∫–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ —á–µ—Ä–µ–∑ —Å–∫–∞–ª—è—Ä–Ω–æ–µ –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ (–≤–µ–∫—Ç–æ—Ä—ã –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω—ã)\n",
        "        # sim = e * g\n",
        "        similarities = np.dot(embeddings, initial_centroid)\n",
        "\n",
        "        # 3. –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ –∫–∞–¥—Ä—ã, –∫–æ—Ç–æ—Ä—ã–µ –ª—É—á—à–µ –ø–æ—Ä–æ–≥–∞ (–æ—Ç—Å–µ–∫–∞–µ–º —Ö—É–¥—à–∏–µ 25%)\n",
        "        threshold = np.percentile(similarities, 100 - percentile)\n",
        "        filtered_embeddings = embeddings[similarities >= threshold]\n",
        "\n",
        "        # 4. –ß–∏—Å—Ç–æ–≤–æ–π —Ü–µ–Ω—Ç—Ä–æ–∏–¥\n",
        "        final_centroid = np.mean(filtered_embeddings, axis=0)\n",
        "        gold_embeddings[person_name] = final_centroid / np.linalg.norm(final_centroid)\n",
        "\n",
        "    return gold_embeddings\n",
        "\n",
        "# –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ–∏–ª—å—Ç—Ä\n",
        "gold_database = create_gold_embeddings(raw_database, percentile=75)\n",
        "\n",
        "# –°–æ—Ö—Ä–∞–Ω—è–µ–º \"–º–æ–∑–≥\"\n",
        "with open(MODEL_PATH, 'wb') as f:\n",
        "    pickle.dump(gold_database, f)\n",
        "\n",
        "print(f\"üéØ –ì–æ—Ç–æ–≤–æ! –ë–∞–∑–∞ –∑–æ–ª–æ—Ç—ã—Ö —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {MODEL_PATH}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hchi_4HpMQ4Y",
        "outputId": "17f0f11a-ede3-4a84-c8d2-7a631356289d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ú® –û—á–∏—Å—Ç–∫–∞ –æ—Ç —à—É–º–∞ –∏ —Å–æ–∑–¥–∞–Ω–∏–µ —ç—Ç–∞–ª–æ–Ω–æ–≤...\n",
            "üéØ –ì–æ—Ç–æ–≤–æ! –ë–∞–∑–∞ –∑–æ–ª–æ—Ç—ã—Ö —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: /content/drive/MyDrive/student_embeddings.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jZ2ZyBMTMgKG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}